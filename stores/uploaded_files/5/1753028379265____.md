# ELK体系

| 组件  | 全称          | 主要功能                               |
| ----- | ------------- | -------------------------------------- |
| **E** | Elasticsearch | 分布式搜索和分析引擎（存储和检索日志） |
| **L** | Logstash      | 日志收集和处理（支持多种格式）         |
| **K** | Kibana        | 数据可视化和仪表盘展示                 |

##  1. **Elasticsearch**

- 一个分布式全文搜索引擎，基于 Lucene 构建。
- 在 ELK 中用来**存储、索引和查询日志数据**。
- 支持强大的查询语言和聚合分析能力。

## 2. **Logstash**

- 一个强大的日志**采集、处理和转发工具**。
- 支持多种输入源（文件、TCP、Kafka 等）、多种过滤处理（正则提取、字段清洗）、以及多种输出（Elasticsearch、文件等）。
- 可以用配置文件灵活定义数据流。

## 3. **Kibana**

- Web UI 工具，用来**可视化 Elasticsearch 中的数据**。
- 提供仪表盘、图表、搜索、过滤器等功能，常用于监控、运维场景。

如果坚持用官方 `go-elasticsearch`，那就继续用自己封装的 `eslogrus`，是兼容性最好的做法。如果使用社区库，可能会出现不兼容的情况。

# Jaeger

Jaeger 是一个用于**分布式链路追踪（Distributed Tracing）**的开源系统，它的主要作用是帮助你：观察微服务之间的调用关系、性能瓶颈和故障点。

**Jaeger = 监控服务之间调用过程的“监视器” + 可视化分析工具**

## 核心功能

| 功能           | 描述                                            |
| -------------- | ----------------------------------------------- |
| 🔗 追踪请求链路 | 展示一次请求从服务A → B → C…全过程              |
| 📊 性能分析     | 显示每一段操作的耗时（哪个环节最慢）            |
| 🐞 故障排查     | 查看错误发生在哪个服务、哪个方法                |
| 🧩 微服务拓扑图 | 自动分析服务依赖关系，生成图                    |
| 🗃️ 数据存储     | 支持将追踪数据存入 Elasticsearch、Kafka、文件等 |

## 实际使用场景举例

假设你有如下微服务：

```
css


复制编辑
[前端] → [API网关] → [用户服务] → [订单服务] → [数据库]
```

用户一次请求下来，Jaeger 可以帮你展示：

- 请求是从哪里来的？
- 调用了哪些服务？
- 每个服务用了多久？
- 哪个环节最慢？
- 是否抛错？

## Jaeger UI 示例

在浏览器打开 `http://localhost:16686`（默认端口），你可以：

- 查询某个 traceID 的完整链路
- 看到所有 span 的耗时和状态
- 搜索某个服务、某个时间段的请求

## 优点

- Uber 开源，稳定可靠
- 支持 OpenTracing 标准
- 和 Prometheus / Grafana / Kubernetes 等很好集成
- 可插拔存储后端（Elasticsearch、Kafka）

## 总结

> **Jaeger 是一套用于监控微服务调用链路的系统，帮助你查看一次请求在各个服务之间的流转过程和耗时情况。**

它在微服务架构中非常重要，是“可观测性三大支柱”之一（Logging、Metrics、Tracing）。

# Span（Track）

在分布式链路追踪（Tracing）中，**`Span` 是追踪的最小单位**，它表示一次**操作过程（调用过程、函数、请求等）**。

你可以把它理解为：

> 一次 API 调用、一次数据库访问、一次函数执行、一次 RPC 请求……都可以表示成一个 `Span`。

## 举例

假设你有这样一个调用链：

```
css复制编辑[客户端请求]
    ↓
[服务 A] --> 调用 --> [服务 B] --> 查询数据库 --> [MySQL]
```

这条调用链可以由多个 `Span` 组成：

| Span 名称      | 描述                   | 是否有父级 Span |
| -------------- | ---------------------- | --------------- |
| HTTP-Request   | 客户端发起请求到服务 A | 无（根 Span）   |
| A → B RPC      | 服务 A 调用服务 B      | 是              |
| B → MySQL 查询 | 服务 B 查询数据库      | 是              |



这些 `Span` 会组成一棵「追踪树」，有时也叫 **Trace**（追踪）。`Span` 是这个树的「节点」，表示每一段操作。

## 代码举例

```go
span := tracer.StartSpan("HTTP Request")
defer span.Finish()

// 做一些事情，比如调用 API
```

StartSpan(name)：创建一个新的 span

Finish()：结束 span（并记录持续时间）

## 总结

> **Span 表示一次具体的操作（函数调用、请求等），在分布式系统中用来标记「这一段」发生了什么。**

它能帮助你追踪整条调用链，定位慢请求、服务瓶颈、错误来源。

# Redis

## RedisClient.Incr

`edisClient.Incr` 是 Redis 客户端中用于 **将某个 key 对应的值自增 1** 的操作，等价于 Redis 命令：

```
redis INCR key
```

一般用于：网站访问量统计、限流计数器（如：每分钟请求数）、分布式唯一编号。

### 基本作用

- 如果 key 不存在，**会先将 key 的值初始化为 0，然后执行自增**，最终值为 `1`。
- 如果 key 已存在且是整数，**直接加 1**。
- 如果 key 的值不是整数（比如字符串、浮点数等），**会报错**。

### 注意事项

- 是 **原子操作**，即多个并发请求也不会冲突。

- 默认情况下，没有过期时间（如果你希望 key 自动失效，需要设置 TTL）。
   可结合 `Expire`：

  ```go
  RedisClient.Expire(ctx, "rate_limit:uid:1234", time.Minute)
  ```

## RedisClient.ZIncrBy

`RedisClient.ZIncrBy` 是 Redis 中 **对有序集合（Sorted Set）中某个成员的分数（score）增加指定值** 的操作。等价于 Redis 命令：

```
ZINCRBY key increment member
```

一般用于：排行榜系统、热度统计、任务优先级累计。

### 作用

对指定 key 的有序集合中某个成员 `member` 的分数加上 `increment`，如果：

- 成员存在：则它的 score 增加 `increment`。
- 成员不存在：则添加该成员，并将 score 设置为 `increment`

### 注意事项

- `ZIncrBy` 操作是 **原子的**，适合高并发环境。
- `increment` 可以是负数，即 **减少分数**。
- 可以为排行榜 key 设置过期时间，避免数据积累过多。

## RedisClient.ZAdd

`ZAdd` 是 Redis 中操作 **有序集合（Sorted Set）** 的一个命令，用于**向有序集合添加一个或多个成员，并设置其分数**。

```go
RedisClient.ZAdd(ctx context.Context, key string, members ...*redis.Z) *redis.IntCmd
```

| 参数名    | 类型              | 含义                                          |
| --------- | ----------------- | --------------------------------------------- |
| `ctx`     | `context.Context` | 上下文，用于控制超时、取消等                  |
| `key`     | `string`          | Redis 有序集合的键名                          |
| `members` | `...*redis.Z`     | 一个或多个要添加的元素和它们的分数（`score`） |

### 功能

```go
type Z struct {
    Score  float64     // 排序用的分数
    Member interface{} // 实际的元素（可以是 string、int 等）
}
```

- 如果 `member` 不存在，就添加；
- 如果 `member` 已存在，就更新它的 `score`；
- 保持集合中所有元素根据 `score` 排序。

### 小结

- `ZAdd` 是向 Redis 的有序集合插入数据的主要命令；
- 支持自动排序；
- 非常适合排行榜、延迟任务、时间序列数据等应用场景。

## RedisClient.LPush

### 作用

将一个或多个值插入到 **Redis 列表（List）** 的 **最左边（头部）**。

```go
func (c *Client) LPush(ctx context.Context, key string, values ...interface{}) *IntCmd
```

参数说明：

- `ctx`: 上下文对象，用于控制取消、超时等。
- `key`: Redis 中列表的 key（如 `"skill_product_list"`）。
- `values`: 要插入的值，可以是一个或多个，比如字符串、JSON、数字等。

返回值：

返回一个 `*redis.IntCmd`，代表命令执行后列表的长度（可使用 `.Result()` 获取结果）。

## RedisClient.Result

### 作用

获取 Redis 命令的执行结果和错误。

```go
func (cmd *IntCmd) Result() (int64, error)
```

使用说明：

由于 Redis 的命令大多数是异步返回结构（如 `*IntCmd`、`*StringCmd` 等），`.Result()` 是 go-redis 提供的统一方式来获取其**结果值和错误信息**。

## RedisClient.LRange

### 作用

`LRange` 是 Redis 的一个常用列表（List）操作命令，在 Go 语言的 go-redis 客户端中用于**获取列表中某一范围内的元素**。

```go
func (c *Client) LRange(ctx context.Context, key string, start, stop int64) *StringSliceCmd
```

| 参数名  | 含义                                                |
| ------- | --------------------------------------------------- |
| `ctx`   | 上下文，用于超时控制或取消操作（`context.Context`） |
| `key`   | Redis 列表的 key，如 `"skill_product_list"`         |
| `start` | 开始索引（从 0 开始）                               |
| `stop`  | 结束索引，`-1` 表示最后一个元素                     |

索引是支持负数的：

- `0` 表示第一个元素；
- `-1` 表示最后一个元素；
- `-2` 表示倒数第二个，以此类推。

## RedisClient.Get

### 作用

从 Redis 中获取一个键（key）对应的字符串值（value）。

```go
func (c *Client) Get(ctx context.Context, key string) *StringCmd
```

### 含义解析：

- **`c *Client`**：Redis 客户端实例，通常是 `RedisClient`；
- **`ctx context.Context`**：上下文对象，用于超时、取消控制；
- **`key string`**：要获取的 Redis 键；
- **返回值 `*StringCmd`**：这是一个命令结果对象，包含实际的值或错误；

通常会这样使用：

```
val, err := RedisClient.Get(ctx, "mykey").Result()
```

# IDL

**接口描述语言**（Interface description language，缩写**IDL**），是用来描述[软件组件](https://zh.m.wikipedia.org/wiki/软件组件)[接口](https://zh.m.wikipedia.org/wiki/介面_(程式設計))的一种[计算机语言](https://zh.m.wikipedia.org/wiki/计算机语言)。IDL通过一种独立于编程语言的方式来描述接口，使得在不同平台上运行的对象和用不同语言编写的程序可以相互通信交流；比如，一个组件用[C++](https://zh.m.wikipedia.org/wiki/C%2B%2B)写成，另一个组件用[Java](https://zh.m.wikipedia.org/wiki/Java)写成。

## proto3 IDL

协议缓冲区（Protocol Buffers）是一种与语言无关、与平台无关的可扩展机制，用于序列化结构化数据。

它类似于 JSON，但体积更小、速度更快，并且能够生成原生语言绑定。您只需定义一次数据的结构，然后就可以使用专门生成的源代码，轻松地使用各种语言在各种数据流中写入和读取结构化数据。

协议缓冲区是定义语言（在 `.proto`文件中创建）、proto 编译器生成的与数据接口的代码、特定于语言的运行时库、写入文件（或通过网络连接发送）的数据的序列化格式以及序列化数据的组合。

```
syntax = "proto3";

message SearchRequest {
  string query = 1;
  int32 page_number = 2;
  int32 results_per_page = 3;
}
```

# Etcd

**etcd**是一个高度一致的**分布式键值存储系统**，它提供了一种可靠的方式来存储分布式系统或机器集群需要访问的数据。它可以在网络分区期间优雅地处理领导者选举，并且能够容忍机器故障，即使是领导者节点本身。

# Salted Hash

**Salted hash（加盐哈希）** 是一种在进行哈希处理前，**向原始数据中添加额外的“盐值（salt）”** 的安全策略，常用于防止如下攻击：

1. **防止彩虹表攻击（Rainbow Table Attack）**：

- 彩虹表是一种预先计算的哈希值查找表。
- 如果不加盐，相同的密码总会产生相同的哈希值，攻击者只需查表即可逆推出密码。
- 加盐后，即使两个用户使用同一个密码，它们的哈希值也不同，从而使彩虹表失效。

2. **增加破解成本**：

- 攻击者必须为每个盐值重新生成整个彩虹表，计算量指数级增加。

# 缓存一致性

## 缓存强一致性

### 定义：

**强一致性**是指：缓存中的数据**始终与数据库保持一致**，只要数据库发生变化，缓存立刻同步更新。

### 实现方式：

1. **先删除缓存，再更新数据库**（不推荐，可能存在并发问题）。
2. **先更新数据库，再删除缓存**（推荐）。
3. 使用 **消息队列 + 订阅监听机制** 实现异步同步更新。
4. 利用 **分布式锁** 保证操作顺序，避免并发更新问题。

### 特点：

- 数据绝对准确。
- 延迟低的系统中可行。
- 实现复杂度较高，需要处理并发和事务一致性。

### 使用场景：

- 金融、电商结算、用户余额等对一致性要求高的系统。

## 缓存弱一致性

### 定义：

**弱一致性**是指：缓存和数据库的数据**可能存在短时间的不一致**，系统并不会强制每次操作都同步更新缓存。

### 实现方式：

1. **定时刷新缓存**（定时从数据库同步）。
2. **设置缓存过期时间**（如 5 分钟）。
3. **延迟更新或异步写入缓存**。
4. **仅读时缓存命中，不命中就从数据库查询并写入缓存（懒加载）**。

### 特点：

- 实现简单、性能高。
- 有数据过期的窗口期。
- 可接受一定时间内数据“陈旧”。

### 使用场景：

- 论坛文章、用户信息、商品列表等不强依赖实时性的系统。

## 总结对比：

| 特性       | 强一致性   | 弱一致性       |
| ---------- | ---------- | -------------- |
| 一致性保障 | 高         | 低             |
| 实现难度   | 高         | 低             |
| 系统开销   | 大         | 小             |
| 数据实时性 | 实时同步   | 有延迟         |
| 适用场景   | 高价值业务 | 可容忍过期业务 |

# Redis分布式锁

## 一、基本原理

Redis 分布式锁的核心是 `SET key value NX PX timeout` 命令：

```bash
SET lock_key unique_value NX PX 30000
```

- `lock_key`：表示锁的名称。
- `unique_value`：是加锁客户端生成的唯一标识（用于解锁时验证身份）。
- `NX`：仅当 key 不存在时才设置，防止重复加锁。
- `PX 30000`：设置锁的过期时间为 30 秒，防止死锁。

加锁成功返回 `OK`，否则返回 nil。

## 二、加锁示意图

```
Client A -----> SET lock_key UUID_A NX PX 30000 ---> Redis: 成功
Client B -----> SET lock_key UUID_B NX PX 30000 ---> Redis: 失败（因为锁已存在）
```

## 三、解锁操作

### 关键点：

> **只有加锁的客户端才能释放锁！**

解锁时需判断 `lock_key` 的值是否为自己的 `unique_value`，防止误删别人的锁。

### 推荐使用 Lua 脚本保证原子性：

```lua
if redis.call("get", KEYS[1]) == ARGV[1] then
  return redis.call("del", KEYS[1])
else
  return 0
end
```

调用示例（Golang）：

```go
lockKey := "lock:order"
uniqueValue := "UUID-123"
luaScript := `
if redis.call("get", KEYS[1]) == ARGV[1] then
	return redis.call("del", KEYS[1])
else
	return 0
end`
result, err := rdb.Eval(ctx, luaScript, []string{lockKey}, uniqueValue).Result()
```

## 四、Redis分布式锁的常见实现方式

### 1. 单节点实现

适用于低并发、非高可用环境。

**优点**：简单，易于实现
**缺点**：Redis 宕机或网络异常会导致锁丢失。

------

### 2. Redlock（Redis 官方推荐）

Redlock 是 Redis 作者提出的一种**高可用分布式锁算法**，基于多个 Redis 实例（一般至少 5 个）。

#### 核心流程：

1. 向 N 个 Redis 实例尝试加锁（快速 SET NX PX）。
2. 获取超过一半实例锁成功即视为加锁成功（例如 3/5 成功）。
3. 设置统一的超时时间避免死锁。
4. 解锁时遍历删除。

#### 缺点：

- 实现复杂。
- 实际环境中可能存在**时钟漂移**和**网络延迟**问题。

> Go 中可以使用开源库 [go-redsync](https://github.com/go-redsync/redsync) 实现 Redlock。

------

## 五、应用场景

- 秒杀库存扣减防超卖
- 单任务防重复执行（如定时任务、发邮件）
- 支付状态更新防重复处理
- 接口幂等性控制

------

## 六、使用建议

| 建议                       | 说明                               |
| -------------------------- | ---------------------------------- |
| 使用唯一值作为锁值         | 防止误删别人的锁                   |
| 设置合理的过期时间         | 防止死锁                           |
| 使用 Lua 脚本原子解锁      | 保证解锁安全                       |
| 加锁失败需重试/等待        | 使用重试机制如 Exponential Backoff |
| 高可用场景建议使用 Redlock | 尤其在 Redis 有主从/集群架构时     |

# Kafka和消息队列MQ

虽然 Kafka 本身是一种消息队列系统，但它和传统的 **消息队列（MQ）**（如 RabbitMQ、ActiveMQ、Redis Stream、RocketMQ）在**理念、架构、使用场景**等方面存在显著区别。

------

## 一句话区分

| Kafka 属于 “**分布式日志系统**” | 传统 MQ 是 “**面向消息传递的中间件**” |
| ------------------------------- | ------------------------------------- |
|                                 |                                       |



------

## 核心区别对比

| 方面                 | Kafka                                         | 传统 MQ（RabbitMQ 等）                   |
| -------------------- | --------------------------------------------- | ---------------------------------------- |
| **设计定位**         | 分布式日志系统（Log），用于高吞吐、高可用场景 | 消息传递系统，注重消息可靠投递、灵活路由 |
| **消息模型**         | 发布-订阅（Pub/Sub）为主                      | 点对点 / 发布-订阅并存，灵活多样         |
| **消息投递机制**     | 消息持久化保存，消费者自行维护 offset         | 消息由 broker 管理，消费后通常会被删除   |
| **是否保留历史消息** | 是（可设置保留时间、甚至永久）                | 否（消费即删除）                         |
| **消费者模型**       | 消费者自己控制 offset，可重复消费             | 默认是消息“投递”后删除，无法重复消费     |
| **高吞吐性能**       | 极高（百万级 TPS）                            | 较低（适合轻量业务）                     |
| **事务支持**         | 支持幂等、exactly-once 需要额外配置           | 天然支持 ACK/NACK、事务操作              |
| **消息顺序**         | 分区内顺序保证，分区间无序                    | 通常不保证顺序（或代价高）               |
| **典型场景**         | 大数据采集、日志系统、流处理（Flink）         | 用户注册、下单通知、即时通信等           |



------

## 举个例子：

### Kafka 使用场景：

> 用户注册后，Kafka 异步通知：
>
> - 记录操作日志
> - 同步用户数据到大数据仓库（如 Hive）
> - 推送到推荐系统构建画像

场景特点：

- 不在乎是否“立即处理”
- 可回放历史消息（日志）
- 关注吞吐量和可扩展性

------

### RabbitMQ 使用场景：

> 用户下单后立即通知：
>
> - 支付系统开始扣款
> - 商家库存系统同步
> - 发送短信提醒

场景特点：

- 需要**确保消息投递成功**
- 要求实时性好
- 多种路由策略（如 topic/exchange）

------

## 二者是否冲突？

**不冲突，可以组合使用！**

- Kafka 适合做“**事件驱动的数据平台**”
- MQ 更适合做“**事务级的业务中台连接器**”

------

## 总结建议

| 需求                             | 推荐方案              |
| -------------------------------- | --------------------- |
| 要求高吞吐、可重放、持久保留日志 | ✅ Kafka               |
| 要求强一致性、事务保障、实时投递 | ✅ RabbitMQ / RocketMQ |
| 数据流处理（Flink、Spark）输入源 | ✅ Kafka               |
| 简单异步处理（发短信、缓存刷新） | ✅ RabbitMQ            |